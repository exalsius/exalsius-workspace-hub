# Test Workspace Helm Chart Values

# DO NOT CHANGE THIS PARAMETER
deploymentNumReplicas: 1

# Deployment configuration

deploymentNamespace: "default"
deploymentImage: "ghcr.io/exalsius/diloco-training:dev"

# Job configuration
deploymentName: "diloco-training-job"

# PyTorch Elastic training configuration with etcd rendezvous
elastic:
  minNodes: 2  # Minimum number of nodes for elastic training
  maxNodes: 3  # Maximum number of nodes for elastic training
  maxRestarts: 3  # Maximum restarts for elastic training
  
  # etcd rendezvous backend configuration
  etcd:
    # External etcd configuration (if using external etcd instead of the embedded subchart)
    externalEndpoint: ""  # e.g., "etcd.infrastructure.svc.cluster.local:2379"
    prefix: "/torchelastic"  # etcd key prefix for job isolation
    protocol: "http"         # "http" or "https"

# Ephemeral storage configuration
ephemeralStorageGb: 50

# Resource configuration for a single worker pod
cpuCores: 2
memoryGb: 8
gpuCountPerNode: 1  # Number of GPUs per node (also determines PyTorch processes per node)

# DiLoCo Training Environment Variables
diloco:
  model: "gpt-neo-x"
  dataset: "c4"
  localSteps: "50"
  lr: "4e-4"
  outerLr: "0.7"
  warmupSteps: "500"
  totalSteps: "1000"
  perDeviceTrainBatchSize: "64"
  batchSize: "512"
  optimMethod: "demo"
  quantization: "false"
  asyncCommunication: "false"
  checkpointPath: "checkpoint.pth"
  checkpointInterval: "512"
  device: "cuda"
  wandbProjectName: "diloco-training"
  wandbGroup: "diloco-gptneo-c4-elastic"
  wandbRunId: "gpt-4e-4"
  heterogeneous: "true"
  minBatchSize: "32"
  maxBatchSize: "512"
  groupPercVariance: "0.15"
  compressionDecay: "0.95"
  compressionTopk: "32"
  experimentDescription: "GPT training on c4 using DiLoCo distributed training"
  experimentTags: "[\"diloco\", \"gpt-neo-x\", \"c4\"]"
  seed: "42"
  wandbLogging: "true"
  wandbUserKey: "XXXXXXXXXXXXXXXXXXXXXXXXXXX"
  huggingfaceToken: "XXXXXXXXXXXXXXXXXXXXXXXX"
  compileModel: "false"
  compileBackend: "inductor"
  compileMode: "default"
  hfUpload: "false"
  trainedModelHfName: ""

# etcd subchart configuration (bitnami/etcd)
# Set enabled: false to use an external etcd cluster (configure elastic.etcd.externalEndpoint)
etcd:
  enabled: true
  replicaCount: 1  
  image:
    registry: docker.io
    repository: bitnamilegacy/etcd
  auth:
    rbac:
      create: false
      rootPassword: ""
    client:
      secureTransport: false
      enableAuthentication: false
  livenessProbe:
    enabled: false  # Disabled to prevent restart loops
  readinessProbe:
    enabled: false  # Disabled to prevent restart loops
  extraEnvVars:
    - name: ETCD_ENABLE_V2
      value: "true"