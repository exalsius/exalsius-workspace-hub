{
    "models": ["gpt2", "meta-llama/Llama-3.2-3B-Instruct", "Qwen/Qwen2.5-3B-Instruct", "google/gemma-3-1b-it", "mistralai/Mistral-7B-Instruct-v0.3", "tiiuae/falcon-7b-instruct"],
    "batch_sizes": [4, 8, 16, 32],
    "seq_lengths": [256, 512, 1024, 2048, 4096],
    "accumulation_steps": [1, 4, 8],
    "optimizers": ["adam", "adamw", "sgd"],
    "input_datasets": ["permutans/fineweb-bbc-news"],
    "use_amp": [true, false],
    "use_ddp": [true, false],
    "use_fuse": [true, false],
    "use_lora": [true, false],
    "num_steps": 30
}