{
    "models": ["gpt2", "meta-llama/Llama-3.2-1B", "meta-llama/Llama-3.2-3B", "meta-llama/Llama-3.2-3B-Instruct", "Qwen/Qwen2.5-3B-Instruct", "google/gemma-3-1b-it"],
    "batch_sizes": [1, 2, 4, 8, 16, 32, 64],
    "seq_lengths": [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192],
    "accumulation_steps": [1, 4, 8],
    "optimizers": ["adam", "adamw", "sgd"],
    "input_datasets": ["permutans/fineweb-bbc-news"],
    "use_amp": [true, false],
    "use_ddp": [true, false],
    "use_fuse": [true, false],
    "use_lora": [true, false],
    "num_steps": 30
}