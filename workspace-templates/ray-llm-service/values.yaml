# Ray LLM Service Helm Chart Values
deploymentImage: "rayproject/ray-ml:2.46.0.0e19ea"

# If you require access to access-restricted models, you can specify a Hugging Face token here.
# huggingfaceToken: "my-hugging-face-token"

# LLM / Ray / vLLM specific configuration
numModelReplicas: 1
runtimeEnvironmentPipPackages: "numpy==1.26.4,vllm==0.9.0,ray==2.46.0"

huggingfaceModel: "microsoft/phi-4"
tensorParallelSize: 1
pipelineParallelSize: 1
placementGroupStrategy: "PACK"
cpuPerActor: 16
gpuPerActor: 1


##################################################################
########## ONLY HERE FOR REFERENCE OR LOCAL TESTING ##############
########## Values are set automatically by exalsius ##############
##################################################################
global:
  deploymentName: "my-llm-service"
  deploymentNamespace: "default"

resources:
  # Ephemeral storage configuration
  ephemeralStorageGb: 50
  # Resource configuration
  cpuCores: 16
  memoryGb: 32
  gpuCount: 1

deploymentNumReplicas: 1