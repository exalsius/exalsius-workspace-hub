# Ray LLM Service Helm Chart Values

# DO NOT CHANGE THIS PARAMETER
deploymentNumReplicas: 1

# Deployment configuration
deploymentName: "my-llm-service"
deploymentNamespace: "default"
deploymentImage: "rayproject/ray-ml:2.46.0.0e19ea"

# If you require access to access-restricted models, you can specify a Hugging Face token here.
# huggingFaceToken: "my-hugging-face-token"

# LLM / Ray / vLLM specific configuration
numModelReplicas: 1
runtimeEnvironmentPipPackages: "numpy==1.26.4,vllm==0.9.0,ray==2.46.0"

llmModelName: "microsoft/phi-4"
tensorParallelSize: 1
pipelineParallelSize: 1
placementGroupStrategy: "PACK"
cpuPerActor: 8
gpuPerActor: 1

# Ephemeral storage configuration
podEphemeralStorageGb: 50

# Resource configuration (this maps to ResourcePool spec in API, but camelcase)
cpuCores: 16
memoryGb: 32
gpuCount: 1
