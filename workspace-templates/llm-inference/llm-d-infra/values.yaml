modelRegistry:
  enabled: true
  replicas: 1
  image:
    repository: ghcr.io/astral-sh/uv
    tag: python3.12-bookworm-slim
    pullPolicy: IfNotPresent
  configMapLabel:
    key: inference.networking.k8s.io/bbr-managed
    value: "true"
  modelsDataKey: baseModel
  pollIntervalSec: "30"
  service:
    type: ClusterIP
    port: 8000
  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

infra:
  gateway:
    enabled: true
    gatewayClassName: istio
    fullnameOverride: llm-d-inference-gateway
    listeners:
      - name: llm-inference
        port: 80
        protocol: HTTP
        allowedRoutes:
          namespaces:
            from: All
    service:
      type: NodePort
    labels:
      gateway-role: llm-inference
    annotations:
      workspace.exalsius.ai/access-info: "true"
      workspace.exalsius.ai/access-type: "nodeport"
      workspace.exalsius.ai/access-description: "Endpoint for LLM inference"
      workspace.exalsius.ai/protocol: "tcp"
      workspace.exalsius.ai/port-name: "llm-inference"
      workspace.exalsius.ai/shared-service: "true"

bbr:
  bbr:
    # Makes it possible to watch for configmaps across namespaces
    multiNamespace: true
  provider:
    name: istio
    istio:
      # Apply EnvoyFilter only to the inference gateway (must match gateway pod labels)
      workloadSelector:
        gateway-role: llm-inference
  inferenceGateway:
    name: llm-d-inference-gateway

ow:
  enableOpenaiApi: true
  openaiBaseApiUrl: http://llm-d-inference-gateway-istio.llm-d.svc.cluster.local:80/v1
  image:
    pullPolicy: Always
  ollama:
    enabled: false
  pipelines:
    enabled: false
  tika:
    enabled: false
  websocket:
    enabled: false

owgateway:
  gatewayClassName: istio
  listeners:
    - name: open-webui
      port: 80
      protocol: HTTP
      allowedRoutes:
        namespaces:
          from: All
  service:
    type: NodePort
  labels:
    gateway-role: open-webui
  annotations:
    workspace.exalsius.ai/access-info: "true"
    workspace.exalsius.ai/access-type: "nodeport"
    workspace.exalsius.ai/access-description: "Endpoint for Open WebUI"
    workspace.exalsius.ai/protocol: "tcp"
    workspace.exalsius.ai/port-name: "open-webui"
    workspace.exalsius.ai/shared-service: "true"
  gatewayParameters:
    logLevel: "warn"